{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Generic inputs for most ML tasks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# This is new\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# setup interactive notebook mode\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# fetch data \n",
    "\n",
    "main_data = pd.read_csv('Kaggle_Data/Stars.csv')\n",
    "main_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coded_data = pd.get_dummies(main_data, drop_first = True)\n",
    "coded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coded_data)\n",
    "set(coded_data['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = coded_data[coded_data['Type'] == 0]\n",
    "X1 = coded_data[coded_data['Type'] == 1]\n",
    "X2 = coded_data[coded_data['Type'] == 2]\n",
    "X3 = coded_data[coded_data['Type'] == 3]\n",
    "X4 = coded_data[coded_data['Type'] == 4]\n",
    "X5 = coded_data[coded_data['Type'] == 5]\n",
    "\n",
    "for col in coded_data.drop(columns=['Type']).columns: \n",
    "    plt.scatter(X0[col], X0['Type'], color = 'red', marker = 'o', label = 'Type 0')\n",
    "    plt.scatter(X1[col], X1['Type'], color = 'blue', marker = '<', label = 'Type 1')\n",
    "    plt.scatter(X2[col], X2['Type'], color = 'orange', marker = 'd', label = 'Type 2')\n",
    "    plt.scatter(X3[col], X3['Type'], color = 'cyan', marker = 'x', label = 'Type 3')\n",
    "    plt.scatter(X4[col], X4['Type'], color = 'black', marker = 'v', label = 'Type 4')\n",
    "    plt.scatter(X5[col], X5['Type'], color = 'green', marker = '+', label = 'Type 5')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Type')\n",
    "    # plt.legend(loc='center right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admission_data.isna().sum()\n",
    "coded_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(coded_data.drop(columns = ['Type']), coded_data['Type'], test_size=0.2, stratify = coded_data['Type'], random_state=50)\n",
    "# In the above split the stratify = y essentially makes sure the fractions of the classification is maintained\n",
    "X_train\n",
    "X_test\n",
    "y_train\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(fit_intercept = True, solver='newton-cg', multi_class = 'multinomial', penalty = 'none', max_iter = 1000)\n",
    "# model = LogisticRegression(fit_intercept = True, solver='lbfgs', multi_class = 'ovr', penalty = 'none', max_iter = 1000)\n",
    "# model = LogisticRegression(fit_intercept = True, solver='lbfgs', multi_class = 'multinomial', penalty = 'none', max_iter = 1000)\n",
    "# model = LogisticRegression(fit_intercept = True, solver='newton-cg', multi_class = 'multinomial', penalty = 'none', max_iter = 10000)\n",
    "\n",
    "# While using multiclass case do multi_class = 'ovr' or 'auto'; can also try other solvers\n",
    "# While doing regularization, use penalty = 'l2' and also C = 10.0 (need to try other values too)\n",
    "\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "# The following gives the mean accuracy on the given data and labels\n",
    "model.score(X_train, y_train) \n",
    "\n",
    "# This is the coefficient Beta_1, ..., Beta_7\n",
    "model.coef_\n",
    "\n",
    "# This is the coefficient Beta_0\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = pd.DataFrame(model.predict(X_test), index = X_test.index, columns = ['pred_Type'])\n",
    "test_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = test_output.merge(y_test, left_index = True, right_index = True)\n",
    "test_output.head()\n",
    "print('Percentage of correct predictions is ')\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = test_output.merge(X_test, left_index = True, right_index = True)\n",
    "test_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(coded_data.drop(columns = ['Type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.predict_proba(coded_data.drop(columns = ['Type'])), columns = [0, 1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.predict_proba(coded_data.drop(columns = ['Type'])), columns = [0, 1, 2, 3, 4, 5]).max(axis = 1)\n",
    "pd.DataFrame(model.predict_proba(coded_data.drop(columns = ['Type'])), columns = [0, 1, 2, 3, 4, 5]).idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_prob = X_train.copy()\n",
    "data_with_prob['Type'] = y_train\n",
    "# Next we give the probability of predicting 1 (in multiclass, there will be probabilities by class)\n",
    "data_with_prob['Probability'] = model.predict_proba(data_with_prob.drop(columns = ['Type'])).max(axis = 1)\n",
    "\n",
    "# Notice that we are changing the probability to the one that was predicted\n",
    "# data_with_prob['Probability'] = model.predict_proba(data_with_prob.drop(columns = ['Type']))[:,1]\n",
    "\n",
    "data_with_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output['Probability'] = model.predict_proba(test_output.drop(columns = ['Type', 'pred_Type'])).max(axis = 1)\n",
    "# Sane as abive here too\n",
    "# test_output['Probability'] = model.predict_proba(test_output.drop(columns = ['Type', 'pred_Type']))[:,1]\n",
    "\n",
    "test_output.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
